{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6snkAQwld0i",
        "outputId": "3e896eaa-8e29-411d-9ccc-2dd5f18f896f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting wave\n",
            "  Downloading Wave-0.0.2.zip (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m928.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, wave\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=05149cab42de46da8bd27519e0880ff9ec0783dfb3ee0022d8d839fed48bffc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for wave (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wave: filename=Wave-0.0.2-py3-none-any.whl size=1220 sha256=88257770a29a9bbcd69c10511187dc4bfa4ffa6f958bff29c1584e5ad7c41154\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/ca/18/1b5c2e79061f666af1114a80567bbfdc72b1d9bcb5a584462c\n",
            "Successfully built langdetect wave\n",
            "Installing collected packages: wave, pydub, watchdog, pyngrok, langdetect, pydeck, streamlit\n",
            "Successfully installed langdetect-1.0.9 pydeck-0.9.1 pydub-0.25.1 pyngrok-7.2.3 streamlit-1.43.2 watchdog-6.0.0 wave-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok google-generativeai langdetect requests pydub wave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fuser -k 8501/tcp"
      ],
      "metadata": {
        "id": "RFMokORC16YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pgrep -a ngrok\n"
      ],
      "metadata": {
        "id": "3YJUiQ7vuFUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill $(pgrep ngrok)\n"
      ],
      "metadata": {
        "id": "Q2cs9IVzuLGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dcf252-416b-4de9-fb27-f875cb600d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2uN0j8QJkDOO4UPNB1Sxy5aLiWw_753JvMhvHRzUJ4NipDZ8K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQyGKK2cln3V",
        "outputId": "e9803c31-05d0-4070-f65f-661d224350ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "import os\n",
        "import wave\n",
        "import re\n",
        "import time\n",
        "from langdetect import detect\n",
        "import google.generativeai as genai\n",
        "from pydub import AudioSegment\n",
        "from google.colab import files\n",
        "\n",
        "# Configure APIs\n",
        "GEMINI_API_KEY = \"AIzaSyB1bst849qK6n6hbTdnCPpqGKFOUahkgu8\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "SARVAM_AI_API = \"299b2a60-2dba-4592-b522-3115d649b58f\"\n",
        "\n",
        "# API Endpoints\n",
        "STT_API_URL = \"https://api.sarvam.ai/speech-to-text-translate\"\n",
        "TTS_API_URL = \"https://api.sarvam.ai/text-to-speech\"\n",
        "TRANSLATE_API_URL = \"https://api.sarvam.ai/translate\"\n",
        "headers = {\"api-subscription-key\": SARVAM_AI_API}\n",
        "\n",
        "# Language Mapping\n",
        "LANGUAGE_MAPPING = {\"hi\": \"hi-IN\", \"bn\": \"bn-IN\", \"kn\": \"kn-IN\", \"ml\": \"ml-IN\",\n",
        "                   \"mr\": \"mr-IN\", \"or\": \"od-IN\", \"pa\": \"pa-IN\", \"ta\": \"ta-IN\",\n",
        "                   \"te\": \"te-IN\", \"en\": \"en-IN\", \"gu\": \"gu-IN\"}\n",
        "\n",
        "# Helper functions\n",
        "def split_audio(audio_data, chunk_duration_ms=5*60*1000):\n",
        "    audio = AudioSegment.from_file(io.BytesIO(audio_data))\n",
        "    return [audio[i:i + chunk_duration_ms] for i in range(0, len(audio), chunk_duration_ms)] or [audio]\n",
        "\n",
        "def translate_audio(audio_data, api_url=STT_API_URL, headers=headers):\n",
        "    chunks = split_audio(audio_data)\n",
        "    responses = []\n",
        "    data = {\"model\": \"saaras:v2\", \"with_diarization\": False}\n",
        "    language = \"en-IN\"  # Default language\n",
        "\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        chunk_buffer = io.BytesIO()\n",
        "        chunk.export(chunk_buffer, format=\"wav\")\n",
        "        chunk_buffer.seek(0)\n",
        "\n",
        "        response = requests.post(api_url, headers=headers,\n",
        "                               files={'file': ('audiofile.wav', chunk_buffer, 'audio/wav')},\n",
        "                               data=data)\n",
        "        if response.status_code in (200, 201):\n",
        "            responses.append(response.json().get(\"transcript\", \"\"))\n",
        "            # Get language from the last chunk's response\n",
        "            language = response.json().get(\"language_code\", \"en-IN\")\n",
        "        else:\n",
        "            st.error(f\"Chunk {idx} processing failed: {response.status_code}\")\n",
        "        chunk_buffer.close()\n",
        "\n",
        "    return \" \".join(responses), language\n",
        "\n",
        "def detect_text_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"en\"\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    return re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "\n",
        "def translate_text(text, source_lang=\"en-IN\", target_lang=\"kn-IN\"):\n",
        "    headers_translate = {\"api-subscription-key\": SARVAM_AI_API, \"Content-Type\": \"application/json\"}\n",
        "    sentences = split_into_sentences(text)\n",
        "    translated_text = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        response = requests.post(TRANSLATE_API_URL, json={\n",
        "            \"source_language_code\": source_lang,\n",
        "            \"target_language_code\": target_lang,\n",
        "            \"speaker_gender\": \"Male\",\n",
        "            \"mode\": \"classic-colloquial\",\n",
        "            \"model\": \"mayura:v1\",\n",
        "            \"enable_preprocessing\": False,\n",
        "            \"input\": sentence\n",
        "        }, headers=headers_translate)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            translated_text += response.json().get(\"translated_text\", \"\") + \" \"\n",
        "        else:\n",
        "            translated_text += \"[Translation Failed] \"\n",
        "        time.sleep(0.2)  # To avoid rate limiting\n",
        "\n",
        "    return translated_text.strip()\n",
        "\n",
        "def text_to_speech(text, lang_code=\"en-IN\"):\n",
        "    chunks = [text[i:i + 500] for i in range(0, len(text), 500)]\n",
        "    audio_data = b\"\"\n",
        "    headers_tts = {\"Content-Type\": \"application/json\", \"api-subscription-key\": SARVAM_AI_API}\n",
        "\n",
        "    for chunk in chunks:\n",
        "        response = requests.post(TTS_API_URL, json={\n",
        "            \"inputs\": [chunk],\n",
        "            \"target_language_code\": lang_code,\n",
        "            \"speaker\": \"neel\",\n",
        "            \"model\": \"bulbul:v1\",\n",
        "            \"pitch\": 0,\n",
        "            \"pace\": 1.0,\n",
        "            \"loudness\": 1.0,\n",
        "            \"enable_preprocessing\": True\n",
        "        }, headers=headers_tts)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            audio_data += base64.b64decode(response.json()[\"audios\"][0])\n",
        "        else:\n",
        "            st.error(f\"TTS Error: {response.status_code}\")\n",
        "\n",
        "    # Save audio to file\n",
        "    audio_file = \"finny_response.wav\"\n",
        "    with wave.open(audio_file, \"wb\") as wav_file:\n",
        "        wav_file.setnchannels(1)\n",
        "        wav_file.setsampwidth(2)\n",
        "        wav_file.setframerate(22050)\n",
        "        wav_file.writeframes(audio_data)\n",
        "\n",
        "    return audio_file\n",
        "\n",
        "def generate_finny_response(user_input, lang_code=\"en-IN\"):\n",
        "    user_name = st.session_state.user_name or \"User\"\n",
        "    prompt = (f\"You're Finny, a friendly and engaging loan advisor chatbot. Be interactive, ask clarifying questions if needed, \"\n",
        "              f\"and offer guidance in an easygoing yet professional tone. Keep your responses dynamic.\\n\\n\"\n",
        "              f\"{user_name}: {user_input}\\n\\nFinny:\")\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "\n",
        "    # If language is not English, translate the response\n",
        "    base_lang = lang_code.split('-')[0]\n",
        "    if base_lang != \"en\":\n",
        "        # Get English equivalent for translation source\n",
        "        source_lang = \"en-IN\"\n",
        "        # Translate to the target language\n",
        "        translated_response = translate_text(response.text.strip(), source_lang, lang_code)\n",
        "        return translated_response\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "def process_audio_file(audio_file):\n",
        "    # Process uploaded audio file\n",
        "    transcript, detected_language = translate_audio(audio_file.getvalue())\n",
        "\n",
        "    # Extract base language code for language detection\n",
        "    base_lang = detected_language.split('-')[0]\n",
        "    short_lang = base_lang if base_lang in LANGUAGE_MAPPING else \"en\"\n",
        "    full_lang_code = LANGUAGE_MAPPING.get(short_lang, \"en-IN\")\n",
        "\n",
        "    # Generate response using Gemini and translate if needed\n",
        "    ai_response = generate_finny_response(transcript, full_lang_code)\n",
        "\n",
        "    # Add to chat history\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"text\": transcript})\n",
        "\n",
        "    # Generate speech in the same language as the detected audio\n",
        "    response_audio = text_to_speech(ai_response, full_lang_code)\n",
        "\n",
        "    st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": ai_response, \"audio\": response_audio})\n",
        "\n",
        "    return transcript, ai_response, response_audio\n",
        "\n",
        "# Initialize session state\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if \"user_name\" not in st.session_state:\n",
        "    st.session_state.user_name = None\n",
        "if \"user_age\" not in st.session_state:\n",
        "    st.session_state.user_age = None\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Finny - Your Friendly Loan Advisor 🤖\")\n",
        "st.write(\"Chat with Finny using text or upload voice recordings. Let's find the best loan options for you!\")\n",
        "\n",
        "# Initial user setup\n",
        "if not st.session_state.user_name:\n",
        "    st.session_state.user_name = st.text_input(\"Hi there! What's your name?\", key=\"name_input\")\n",
        "    if st.session_state.user_name:\n",
        "        st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": f\"Nice to meet you, {st.session_state.user_name}! How old are you?\"})\n",
        "        st.rerun()\n",
        "elif not st.session_state.user_age:\n",
        "    st.session_state.user_age = st.text_input(f\"Great, {st.session_state.user_name}! How old are you?\", key=\"age_input\")\n",
        "    if st.session_state.user_age:\n",
        "        st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": f\"Awesome, {st.session_state.user_name}! Now, how can I assist you with loans today?\"})\n",
        "        st.rerun()\n",
        "\n",
        "# Chat display\n",
        "for message in st.session_state.chat_history:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"text\"])\n",
        "        if \"audio\" in message:\n",
        "            st.audio(message[\"audio\"], format='audio/wav')\n",
        "\n",
        "# User interaction area\n",
        "if st.session_state.user_name and st.session_state.user_age:\n",
        "    # Two tabs: Text Chat and Audio Upload\n",
        "    tab1, tab2 = st.tabs([\"Text Chat\", \"Audio Upload\"])\n",
        "\n",
        "    with tab1:\n",
        "        # Text input from user\n",
        "        user_input = st.chat_input(\"Type your message...\")\n",
        "        if user_input:\n",
        "            st.session_state.chat_history.append({\"role\": \"user\", \"text\": user_input})\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.markdown(user_input)\n",
        "\n",
        "            detected_lang = detect_text_language(user_input)\n",
        "            lang_code = LANGUAGE_MAPPING.get(detected_lang, \"en-IN\")\n",
        "            response_text = generate_finny_response(user_input, lang_code)\n",
        "            response_audio = text_to_speech(response_text, lang_code)\n",
        "\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": response_text, \"audio\": response_audio})\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(response_text)\n",
        "                st.audio(response_audio, format='audio/wav')\n",
        "\n",
        "    with tab2:\n",
        "        # Audio file upload\n",
        "        uploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"wav\", \"mp3\", \"ogg\"])\n",
        "        if uploaded_file is not None:\n",
        "            st.audio(uploaded_file, format=f'audio/{uploaded_file.type.split(\"/\")[1]}')\n",
        "\n",
        "            if st.button(\"Process Audio\"):\n",
        "                with st.spinner(\"Processing audio file...\"):\n",
        "                    transcript, response, audio_path = process_audio_file(uploaded_file)\n",
        "                    st.success(\"Audio processed successfully!\")\n",
        "\n",
        "                    with st.expander(\"View Transcript\"):\n",
        "                        st.write(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWJ8cZvBlsu4",
        "outputId": "de16d7cd-fac8-4c4d-fc24-1a9146c7e17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any previous processes\n",
        "!pkill -f streamlit || true\n",
        "!pkill -f ngrok || true\n",
        "!fuser -k 8501/tcp || true\n",
        "\n",
        "# Start Streamlit in the background\n",
        "!nohup streamlit run app.py &\n",
        "\n",
        "# Wait for Streamlit to initialize\n",
        "import time\n",
        "print(\"Waiting for Streamlit to initialize...\")\n",
        "time.sleep(15)\n",
        "\n",
        "# Create a public URL\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"\\n🔗 Your Finny chatbot is running at: {public_url}\")\n",
        "print(\"\\nKeep this notebook running to maintain the connection!\")"
      ],
      "metadata": {
        "id": "QR9995OylzfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5f9f1c-e128-47c4-b3df-08dcdd69f9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n",
            "nohup: appending output to 'nohup.out'\n",
            "Waiting for Streamlit to initialize...\n",
            "\n",
            "🔗 Your Finny chatbot is running at: https://d836-34-23-43-152.ngrok-free.app\n",
            "\n",
            "Keep this notebook running to maintain the connection!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whHoE-_Z0Vwt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}